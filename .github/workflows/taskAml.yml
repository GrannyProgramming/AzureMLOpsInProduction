name: Azure ML Workflow
on:
  push:
    branches:
      - main
    
jobs:
  build:
    runs-on: ubuntu-latest
    strategy:
      matrix:
        environment: [dev] #[dev, test, prod]
    steps:
      - name: Checkout code
        uses: actions/checkout@v3
      
      - name: Set up Python 3.9
        uses: actions/setup-python@v4
        with:
          python-version: 3.9
        
      - name: Install dependencies
        run: python3 .github/utils/installDependencies.py

      - name: Build wheel and install helper functions
        run: |
          cd .github/utils/pyWheels
          python3 setup.py bdist_wheel
          for whl in $(find dist -name "*.whl"); do python -m pip install $whl; done
      
      - name: Set Env Variables
        run: | 
          python3 .github/utils/setEnvVariables.py variables/${{ matrix.environment }}/parameters/parameters.json "['workspace_name=mlw-amcg0002-gwxp', 'resource_group=aml-dev-rg-001']"

      - name: Azure login
        run: |
          echo ${{ secrets.ARM_CLIENT_ID }}
          az login --service-principal \
          --username "${{ secrets.ARM_CLIENT_ID }}" \
          --password "${{ secrets.ARM_CLIENT_SECRET }}" \
          --tenant "${{ secrets.ARM_TENANT_ID }}"
      
      # This needs rethinking, as when moving between the JSON-schema files will be replicated
      - name: Json schema validation
        run: |
          python3 .github/utils/jsonSchemaValidator.py variables/${{ matrix.environment }}

      # commented for faster compile in gh actions
      # - name: Compile Bicep templates
      #   run: |
      #     bicep build ./core/infra/main.bicep

      # - name: Deploy Bicep templates
      #   run: |
      #     python3 .github/utils/createAzureResources.py

      # Create Cluster  - Done, having issues with creating the kubernetes compute and AKS compute. Create seperate script for this.
      - name: Create AML instance/compute Clusters
        env:
          ENVIRONMENT: ${{ matrix.environment }}
        run: | 
          python3 .github/utils/createCompute.py

      # Create mltable, OPTIONAL
      # Does this make sense to have here? As it will mean it will be created everytime the pipeline is run.
      # This will refresh the mltable everytime the pipeline is run though, which is good.
      # Myabe just leave it in here as an example of how to create an mltable.  
      - name: Create an mltable 
        env:
          ENVIRONMENT: ${{ matrix.environment }}
        run: | 
          python3 dataEngineer/createMlTable.py dataScience/src/data

      # Create data asseets, 
      - name: Create data asseets
        env:
          ENVIRONMENT: ${{ matrix.environment }}
        run: | 
          python3 .github/utils/createDataAsset.py variables/dev/dataAssests/dataAssets.json

# ToDo (Core - High priority)
# Create Cluster  - Done, having issues with creating the kubernetes compute and AKS compute.
# Create mltable - Done
# Create data asseets  - Done 
# Create environments - Done
# Create pipeline - Started (50%, needs debugging)
# Create components - Started (50%, needs debugging)
# Model deployment - Not Started
# Monitoring - 20% (created the LAW and seperate rg)
# Testing - Not Started
          # Unit testing - Not Started "Mocking"
          # Integration testing - Not Started
          # End to end testing - Not Started
# CI/CD - Not Started
          # Git Config for AML 
          # Create Repos in AML 
          # Repo Pull  - get most up to date repo? do we need? needs checking.
          # Use gh CLI for branch creation, testing etc

# Nice to haves (Medium priority)
# RETRAINING - Not Started
# feature tables - Not Started
# Generate Python Wheel Files same as Cia (50% done, needs testing)  
# Git Config for AML 
# Create Repos in AML 
# Repo Pull  - get most up to date repo? do we need? needs checking.



# ToDo (Long-Term priority)
# add gh environments for dev, test, prod (90% done, just needs testing and to publish repo from private into public)
# Secret Scopes/GH Token? Not sure if I need to save the sp details to key vault for the git integration between aml and gh. Same for gh token.  
# Repo Pull  - get most up to date repo? do we need? needs checking.
# Optimising the accelerator
# Terraform for infra
# Managed identity & Access management
# RBAC Assignments: Nice to have, not essential right now , to implement we would need to set up security groups or managed identity and assign roles to them. 
# Advanced datascience features - triton, onnx, ray, azure arc, tpi, etc.,
# enTERPRISE 